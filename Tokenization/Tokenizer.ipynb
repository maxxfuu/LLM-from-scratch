{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary dependecies \n",
    "import re # regular expression to check if theres a pattern \n",
    "import tiktoken # Implementing Byte Pair Encoding using exisitng open-source library \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if Mac supports PyTorch Acceleration with Apple Silicon Chip \n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer: \n",
    "    def __init__(self, vocab):\n",
    "        self.string_to_integer = vocab\n",
    "        self.integer_to_string = {i:s for s,i in vocab.items()} \n",
    "        \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)  # Split text by specific punctuation and whitespace\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]  # Strip and filter out empty items\n",
    "        preprocessed = [item if item in self.string_to_integer else \"<|unk|>\" for item in preprocessed]\n",
    "\n",
    "        ids = [self.string_to_integer[s] for s in preprocessed if s in self.string_to_integer]  # Map the text to ids\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids): \n",
    "        text = \" \".join([self.integer_to_string[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride): \n",
    "        self.input_ids = []\n",
    "        self.target_ids = [] \n",
    "        \n",
    "        token_ids = tokenizer.encode(txt, allowed_special = {\"|endoftext|>\"}) \n",
    "        \n",
    "        for i in range(0, len(token_ids) - max_length, stride): # Creating context window \n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk)) # Creates a input matricies  \n",
    "            self.target_ids.append(torch.tensor(target_chunk)) # Creates a input matricies  \n",
    "            \n",
    "    def __len__(self): \n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size =4, max_length=256, stride=128, shuffle=True, drop_last=True, num_worker = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\") \n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last, \n",
    "        num_workers=num_worker)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '\"': 1,\n",
       " \"'\": 2,\n",
       " '(': 3,\n",
       " ')': 4,\n",
       " '*': 5,\n",
       " ',': 6,\n",
       " '--': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '16': 11,\n",
       " '1908': 12,\n",
       " '1929': 13,\n",
       " '2024': 14,\n",
       " '4': 15,\n",
       " ':': 16,\n",
       " ';': 17,\n",
       " '?': 18,\n",
       " 'A': 19,\n",
       " 'About': 20,\n",
       " 'Ah': 21,\n",
       " 'Among': 22,\n",
       " 'And': 23,\n",
       " 'Are': 24,\n",
       " 'Arrt': 25,\n",
       " 'As': 26,\n",
       " 'At': 27,\n",
       " 'Attribution-ShareAlike': 28,\n",
       " 'Be': 29,\n",
       " 'Begin': 30,\n",
       " 'Burlington': 31,\n",
       " 'But': 32,\n",
       " 'By': 33,\n",
       " 'Carlo': 34,\n",
       " 'Chicago': 35,\n",
       " 'Claude': 36,\n",
       " 'Come': 37,\n",
       " 'Commons': 38,\n",
       " 'Creative': 39,\n",
       " 'Croft': 40,\n",
       " 'Destroyed': 41,\n",
       " 'Devonshire': 42,\n",
       " 'Don': 43,\n",
       " 'Dubarry': 44,\n",
       " 'During': 45,\n",
       " 'Edith': 46,\n",
       " 'Emperors': 47,\n",
       " 'Exported': 48,\n",
       " 'FDL': 49,\n",
       " 'Florence': 50,\n",
       " 'For': 51,\n",
       " 'GNU': 52,\n",
       " 'Gallery': 53,\n",
       " 'Gideon': 54,\n",
       " 'Gisburn': 55,\n",
       " 'Gisburns': 56,\n",
       " 'Grafton': 57,\n",
       " 'Greek': 58,\n",
       " 'Grindle': 59,\n",
       " 'Grindles': 60,\n",
       " 'HAD': 61,\n",
       " 'Had': 62,\n",
       " 'Hang': 63,\n",
       " 'Has': 64,\n",
       " 'He': 65,\n",
       " 'Her': 66,\n",
       " 'Hermia': 67,\n",
       " 'His': 68,\n",
       " 'How': 69,\n",
       " 'I': 70,\n",
       " 'If': 71,\n",
       " 'In': 72,\n",
       " 'It': 73,\n",
       " 'Jack': 74,\n",
       " 'January': 75,\n",
       " 'Jove': 76,\n",
       " 'Just': 77,\n",
       " 'Lord': 78,\n",
       " 'Made': 79,\n",
       " 'Miss': 80,\n",
       " 'Money': 81,\n",
       " 'Monte': 82,\n",
       " 'Moon-dancers': 83,\n",
       " 'Mr': 84,\n",
       " 'Mrs': 85,\n",
       " 'My': 86,\n",
       " 'Never': 87,\n",
       " 'No': 88,\n",
       " 'Now': 89,\n",
       " 'Nutley': 90,\n",
       " 'Of': 91,\n",
       " 'Oh': 92,\n",
       " 'On': 93,\n",
       " 'Once': 94,\n",
       " 'Only': 95,\n",
       " 'Or': 96,\n",
       " 'Perhaps': 97,\n",
       " 'Poor': 98,\n",
       " 'Professional': 99,\n",
       " 'Renaissance': 100,\n",
       " 'Rickham': 101,\n",
       " 'Riviera': 102,\n",
       " 'Rome': 103,\n",
       " 'Russian': 104,\n",
       " 'September': 105,\n",
       " 'Sevres': 106,\n",
       " 'She': 107,\n",
       " 'States': 108,\n",
       " 'Stroud': 109,\n",
       " 'Strouds': 110,\n",
       " 'Suddenly': 111,\n",
       " 'That': 112,\n",
       " 'The': 113,\n",
       " 'Then': 114,\n",
       " 'There': 115,\n",
       " 'They': 116,\n",
       " 'This': 117,\n",
       " 'Those': 118,\n",
       " 'Though': 119,\n",
       " 'Thwing': 120,\n",
       " 'Thwings': 121,\n",
       " 'To': 122,\n",
       " 'United': 123,\n",
       " 'Unported': 124,\n",
       " 'Usually': 125,\n",
       " 'Venetian': 126,\n",
       " 'Verdict': 127,\n",
       " 'Victor': 128,\n",
       " 'Was': 129,\n",
       " 'We': 130,\n",
       " 'Well': 131,\n",
       " 'Wharton': 132,\n",
       " 'What': 133,\n",
       " 'When': 134,\n",
       " 'Why': 135,\n",
       " 'Wikisource': 136,\n",
       " 'Yes': 137,\n",
       " 'You': 138,\n",
       " '[The': 139,\n",
       " ']': 140,\n",
       " '_': 141,\n",
       " 'a': 142,\n",
       " 'abdication': 143,\n",
       " 'able': 144,\n",
       " 'about': 145,\n",
       " 'above': 146,\n",
       " 'abruptly': 147,\n",
       " 'absolute': 148,\n",
       " 'absorbed': 149,\n",
       " 'absurdity': 150,\n",
       " 'academic': 151,\n",
       " 'accessible': 152,\n",
       " 'accuse': 153,\n",
       " 'accustomed': 154,\n",
       " 'across': 155,\n",
       " 'activity': 156,\n",
       " 'add': 157,\n",
       " 'added': 158,\n",
       " 'admirers': 159,\n",
       " 'adopted': 160,\n",
       " 'adulation': 161,\n",
       " 'advance': 162,\n",
       " 'aesthetic': 163,\n",
       " 'affect': 164,\n",
       " 'afraid': 165,\n",
       " 'after': 166,\n",
       " 'afterward': 167,\n",
       " 'again': 168,\n",
       " 'ago': 169,\n",
       " 'ah': 170,\n",
       " 'air': 171,\n",
       " 'alive': 172,\n",
       " 'all': 173,\n",
       " 'almost': 174,\n",
       " 'alone': 175,\n",
       " 'along': 176,\n",
       " 'always': 177,\n",
       " 'am': 178,\n",
       " 'amazement': 179,\n",
       " 'amid': 180,\n",
       " 'among': 181,\n",
       " 'amplest': 182,\n",
       " 'amusing': 183,\n",
       " 'an': 184,\n",
       " 'and': 185,\n",
       " 'another': 186,\n",
       " 'answer': 187,\n",
       " 'answered': 188,\n",
       " 'any': 189,\n",
       " 'anything': 190,\n",
       " 'anywhere': 191,\n",
       " 'apparent': 192,\n",
       " 'apparently': 193,\n",
       " 'appearance': 194,\n",
       " 'appeared': 195,\n",
       " 'apply': 196,\n",
       " 'appointed': 197,\n",
       " 'are': 198,\n",
       " 'areas': 199,\n",
       " 'arm': 200,\n",
       " 'arm-chair': 201,\n",
       " 'arm-chairs': 202,\n",
       " 'arms': 203,\n",
       " 'art': 204,\n",
       " 'articles': 205,\n",
       " 'artist': 206,\n",
       " 'as': 207,\n",
       " 'aside': 208,\n",
       " 'asked': 209,\n",
       " 'at': 210,\n",
       " 'atmosphere': 211,\n",
       " 'atom': 212,\n",
       " 'attack': 213,\n",
       " 'attention': 214,\n",
       " 'attitude': 215,\n",
       " 'audacities': 216,\n",
       " 'away': 217,\n",
       " 'awful': 218,\n",
       " 'axioms': 219,\n",
       " 'azaleas': 220,\n",
       " 'back': 221,\n",
       " 'background': 222,\n",
       " 'balance': 223,\n",
       " 'balancing': 224,\n",
       " 'balustraded': 225,\n",
       " 'basking': 226,\n",
       " 'bath-rooms': 227,\n",
       " 'be': 228,\n",
       " 'beaming': 229,\n",
       " 'bean-stalk': 230,\n",
       " 'bear': 231,\n",
       " 'beard': 232,\n",
       " 'beauty': 233,\n",
       " 'became': 234,\n",
       " 'because': 235,\n",
       " 'becoming': 236,\n",
       " 'bed': 237,\n",
       " 'been': 238,\n",
       " 'before': 239,\n",
       " 'began': 240,\n",
       " 'begun': 241,\n",
       " 'behind': 242,\n",
       " 'being': 243,\n",
       " 'believed': 244,\n",
       " 'beneath': 245,\n",
       " 'bespoke': 246,\n",
       " 'better': 247,\n",
       " 'between': 248,\n",
       " 'big': 249,\n",
       " 'bits': 250,\n",
       " 'bitterness': 251,\n",
       " 'blocked': 252,\n",
       " 'book': 253,\n",
       " 'books': 254,\n",
       " 'born': 255,\n",
       " 'borne': 256,\n",
       " 'boudoir': 257,\n",
       " 'bravura': 258,\n",
       " 'break': 259,\n",
       " 'breaking': 260,\n",
       " 'breathing': 261,\n",
       " 'bric-a-brac': 262,\n",
       " 'briefly': 263,\n",
       " 'brings': 264,\n",
       " 'bronzes': 265,\n",
       " 'brought': 266,\n",
       " 'brown': 267,\n",
       " 'brush': 268,\n",
       " 'built': 269,\n",
       " 'bull': 270,\n",
       " 'business': 271,\n",
       " 'but': 272,\n",
       " 'buying': 273,\n",
       " 'by': 274,\n",
       " 'called': 275,\n",
       " 'came': 276,\n",
       " 'can': 277,\n",
       " 'canvas': 278,\n",
       " 'canvases': 279,\n",
       " 'cards': 280,\n",
       " 'care': 281,\n",
       " 'career': 282,\n",
       " 'caught': 283,\n",
       " 'central': 284,\n",
       " 'chair': 285,\n",
       " 'chap': 286,\n",
       " 'characteristic': 287,\n",
       " 'charming': 288,\n",
       " 'cheap': 289,\n",
       " 'check': 290,\n",
       " 'cheeks': 291,\n",
       " 'chest': 292,\n",
       " 'chimney-piece': 293,\n",
       " 'choice': 294,\n",
       " 'chucked': 295,\n",
       " 'cigar': 296,\n",
       " 'cigarette': 297,\n",
       " 'cigars': 298,\n",
       " 'circulation': 299,\n",
       " 'circumstance': 300,\n",
       " 'circus-clown': 301,\n",
       " 'claimed': 302,\n",
       " 'clasping': 303,\n",
       " 'clear': 304,\n",
       " 'cleverer': 305,\n",
       " 'close': 306,\n",
       " 'clue': 307,\n",
       " 'coat': 308,\n",
       " 'collapsed': 309,\n",
       " 'collection': 310,\n",
       " 'colour': 311,\n",
       " 'come': 312,\n",
       " 'comes': 313,\n",
       " 'comfortable': 314,\n",
       " 'coming': 315,\n",
       " 'commercial': 316,\n",
       " 'committed': 317,\n",
       " 'companion': 318,\n",
       " 'compared': 319,\n",
       " 'complex': 320,\n",
       " 'confident': 321,\n",
       " 'congesting': 322,\n",
       " 'conjugal': 323,\n",
       " 'constantly': 324,\n",
       " 'constraint': 325,\n",
       " 'consummate': 326,\n",
       " 'contended': 327,\n",
       " 'continued': 328,\n",
       " 'contributed': 329,\n",
       " 'contributors': 330,\n",
       " 'copyright': 331,\n",
       " 'copyrighted': 332,\n",
       " 'corner': 333,\n",
       " 'corrected': 334,\n",
       " 'could': 335,\n",
       " 'couldn': 336,\n",
       " 'count': 337,\n",
       " 'countenance': 338,\n",
       " 'countries': 339,\n",
       " 'couple': 340,\n",
       " 'course': 341,\n",
       " 'covered': 342,\n",
       " 'craft': 343,\n",
       " 'cried': 344,\n",
       " 'crossed': 345,\n",
       " 'crowned': 346,\n",
       " 'crumbled': 347,\n",
       " 'cry': 348,\n",
       " 'cured': 349,\n",
       " 'curiosity': 350,\n",
       " 'curious': 351,\n",
       " 'current': 352,\n",
       " 'curtains': 353,\n",
       " 'd': 354,\n",
       " 'dabble': 355,\n",
       " 'damask': 356,\n",
       " 'dark': 357,\n",
       " 'dashed': 358,\n",
       " 'day': 359,\n",
       " 'days': 360,\n",
       " 'dead': 361,\n",
       " 'deadening': 362,\n",
       " 'dear': 363,\n",
       " 'deep': 364,\n",
       " 'deerhound': 365,\n",
       " 'degree': 366,\n",
       " 'delicate': 367,\n",
       " 'demand': 368,\n",
       " 'denied': 369,\n",
       " 'deploring': 370,\n",
       " 'deprecating': 371,\n",
       " 'deprecatingly': 372,\n",
       " 'desire': 373,\n",
       " 'destroyed': 374,\n",
       " 'destruction': 375,\n",
       " 'desultory': 376,\n",
       " 'detail': 377,\n",
       " 'developing': 378,\n",
       " 'diagnosis': 379,\n",
       " 'did': 380,\n",
       " 'didn': 381,\n",
       " 'died': 382,\n",
       " 'digital': 383,\n",
       " 'dim': 384,\n",
       " 'dimmest': 385,\n",
       " 'dingy': 386,\n",
       " 'dining-room': 387,\n",
       " 'disarming': 388,\n",
       " 'discovery': 389,\n",
       " 'discrimination': 390,\n",
       " 'discussion': 391,\n",
       " 'disdain': 392,\n",
       " 'disdained': 393,\n",
       " 'disease': 394,\n",
       " 'disguised': 395,\n",
       " 'display': 396,\n",
       " 'dissatisfied': 397,\n",
       " 'distinguished': 398,\n",
       " 'distract': 399,\n",
       " 'distribute': 400,\n",
       " 'divert': 401,\n",
       " 'do': 402,\n",
       " 'doesn': 403,\n",
       " 'doing': 404,\n",
       " 'domain': 405,\n",
       " 'domestic': 406,\n",
       " 'don': 407,\n",
       " 'done': 408,\n",
       " 'donkey': 409,\n",
       " 'down': 410,\n",
       " 'dozen': 411,\n",
       " 'dragged': 412,\n",
       " 'drawing-room': 413,\n",
       " 'drawing-rooms': 414,\n",
       " 'drawn': 415,\n",
       " 'dress-closets': 416,\n",
       " 'drew': 417,\n",
       " 'dropped': 418,\n",
       " 'e-book': 419,\n",
       " 'e-books': 420,\n",
       " 'each': 421,\n",
       " 'earth': 422,\n",
       " 'ease': 423,\n",
       " 'easel': 424,\n",
       " 'easy': 425,\n",
       " 'echoed': 426,\n",
       " 'economy': 427,\n",
       " 'edition': 428,\n",
       " 'effect': 429,\n",
       " 'effects': 430,\n",
       " 'efforts': 431,\n",
       " 'egregious': 432,\n",
       " 'eighteenth-century': 433,\n",
       " 'elbow': 434,\n",
       " 'elegant': 435,\n",
       " 'else': 436,\n",
       " 'embarrassed': 437,\n",
       " 'enabled': 438,\n",
       " 'end': 439,\n",
       " 'endless': 440,\n",
       " 'enjoy': 441,\n",
       " 'enlightenment': 442,\n",
       " 'enough': 443,\n",
       " 'ensuing': 444,\n",
       " 'equally': 445,\n",
       " 'equanimity': 446,\n",
       " 'errors': 447,\n",
       " 'escape': 448,\n",
       " 'established': 449,\n",
       " 'etching': 450,\n",
       " 'even': 451,\n",
       " 'event': 452,\n",
       " 'ever': 453,\n",
       " 'everlasting': 454,\n",
       " 'every': 455,\n",
       " 'exasperated': 456,\n",
       " 'except': 457,\n",
       " 'excuse': 458,\n",
       " 'excusing': 459,\n",
       " 'existed': 460,\n",
       " 'expected': 461,\n",
       " 'exploitation': 462,\n",
       " 'exquisite': 463,\n",
       " 'exquisitely': 464,\n",
       " 'extenuation': 465,\n",
       " 'exterminating': 466,\n",
       " 'extracting': 467,\n",
       " 'eye': 468,\n",
       " 'eyebrows': 469,\n",
       " 'eyes': 470,\n",
       " 'face': 471,\n",
       " 'faces': 472,\n",
       " 'fact': 473,\n",
       " 'faded': 474,\n",
       " 'failed': 475,\n",
       " 'failure': 476,\n",
       " 'fair': 477,\n",
       " 'faith': 478,\n",
       " 'false': 479,\n",
       " 'familiar': 480,\n",
       " 'famille-verte': 481,\n",
       " 'fancy': 482,\n",
       " 'fashionable': 483,\n",
       " 'fate': 484,\n",
       " 'feather': 485,\n",
       " 'feet': 486,\n",
       " 'fell': 487,\n",
       " 'fellow': 488,\n",
       " 'felt': 489,\n",
       " 'few': 490,\n",
       " 'fewer': 491,\n",
       " 'finality': 492,\n",
       " 'find': 493,\n",
       " 'fingers': 494,\n",
       " 'first': 495,\n",
       " 'fit': 496,\n",
       " 'fitting': 497,\n",
       " 'five': 498,\n",
       " 'flash': 499,\n",
       " 'flashed': 500,\n",
       " 'florid': 501,\n",
       " 'flowers': 502,\n",
       " 'fluently': 503,\n",
       " 'flung': 504,\n",
       " 'follow': 505,\n",
       " 'followed': 506,\n",
       " 'following': 507,\n",
       " 'fond': 508,\n",
       " 'footstep': 509,\n",
       " 'for': 510,\n",
       " 'forced': 511,\n",
       " 'forcing': 512,\n",
       " 'forehead': 513,\n",
       " 'foreign': 514,\n",
       " 'foreseen': 515,\n",
       " 'forgive': 516,\n",
       " 'forgotten': 517,\n",
       " 'form': 518,\n",
       " 'formed': 519,\n",
       " 'forming': 520,\n",
       " 'forward': 521,\n",
       " 'fostered': 522,\n",
       " 'found': 523,\n",
       " 'foundations': 524,\n",
       " 'fragment': 525,\n",
       " 'fragments': 526,\n",
       " 'frame': 527,\n",
       " 'frames': 528,\n",
       " 'free': 529,\n",
       " 'frequently': 530,\n",
       " 'friend': 531,\n",
       " 'from': 532,\n",
       " 'full': 533,\n",
       " 'fullest': 534,\n",
       " 'furiously': 535,\n",
       " 'furrowed': 536,\n",
       " 'garlanded': 537,\n",
       " 'garlands': 538,\n",
       " 'gave': 539,\n",
       " 'genial': 540,\n",
       " 'genius': 541,\n",
       " 'gesture': 542,\n",
       " 'get': 543,\n",
       " 'getting': 544,\n",
       " 'give': 545,\n",
       " 'given': 546,\n",
       " 'glad': 547,\n",
       " 'glanced': 548,\n",
       " 'glimpse': 549,\n",
       " 'gloried': 550,\n",
       " 'glory': 551,\n",
       " 'go': 552,\n",
       " 'going': 553,\n",
       " 'gone': 554,\n",
       " 'good': 555,\n",
       " 'good-breeding': 556,\n",
       " 'good-humoured': 557,\n",
       " 'got': 558,\n",
       " 'grace': 559,\n",
       " 'gradually': 560,\n",
       " 'gray': 561,\n",
       " 'grayish': 562,\n",
       " 'great': 563,\n",
       " 'greatest': 564,\n",
       " 'greatness': 565,\n",
       " 'grew': 566,\n",
       " 'groping': 567,\n",
       " 'growing': 568,\n",
       " 'had': 569,\n",
       " 'hadn': 570,\n",
       " 'hair': 571,\n",
       " 'half': 572,\n",
       " 'half-light': 573,\n",
       " 'half-mechanically': 574,\n",
       " 'hall': 575,\n",
       " 'hand': 576,\n",
       " 'hands': 577,\n",
       " 'handsome': 578,\n",
       " 'hanging': 579,\n",
       " 'happen': 580,\n",
       " 'happened': 581,\n",
       " 'hard': 582,\n",
       " 'hardly': 583,\n",
       " 'has': 584,\n",
       " 'have': 585,\n",
       " 'haven': 586,\n",
       " 'having': 587,\n",
       " 'he': 588,\n",
       " 'head': 589,\n",
       " 'hear': 590,\n",
       " 'heard': 591,\n",
       " 'heart': 592,\n",
       " 'height': 593,\n",
       " 'her': 594,\n",
       " 'here': 595,\n",
       " 'hermit': 596,\n",
       " 'herself': 597,\n",
       " 'hesitations': 598,\n",
       " 'hide': 599,\n",
       " 'high': 600,\n",
       " 'him': 601,\n",
       " 'himself': 602,\n",
       " 'hint': 603,\n",
       " 'his': 604,\n",
       " 'history': 605,\n",
       " 'holding': 606,\n",
       " 'home': 607,\n",
       " 'honour': 608,\n",
       " 'hooded': 609,\n",
       " 'hostess': 610,\n",
       " 'hot-house': 611,\n",
       " 'hour': 612,\n",
       " 'hours': 613,\n",
       " 'house': 614,\n",
       " 'how': 615,\n",
       " 'hung': 616,\n",
       " 'husband': 617,\n",
       " 'idea': 618,\n",
       " 'idle': 619,\n",
       " 'idling': 620,\n",
       " 'if': 621,\n",
       " 'immediately': 622,\n",
       " 'in': 623,\n",
       " 'incense': 624,\n",
       " 'including': 625,\n",
       " 'indifferent': 626,\n",
       " 'inevitable': 627,\n",
       " 'inevitably': 628,\n",
       " 'inflexible': 629,\n",
       " 'insensible': 630,\n",
       " 'insignificant': 631,\n",
       " 'instinctively': 632,\n",
       " 'instructive': 633,\n",
       " 'interesting': 634,\n",
       " 'into': 635,\n",
       " 'ironic': 636,\n",
       " 'irony': 637,\n",
       " 'irrelevance': 638,\n",
       " 'irrevocable': 639,\n",
       " 'is': 640,\n",
       " 'it': 641,\n",
       " 'its': 642,\n",
       " 'itself': 643,\n",
       " 'jardiniere': 644,\n",
       " 'jealousy': 645,\n",
       " 'just': 646,\n",
       " 'keep': 647,\n",
       " 'kept': 648,\n",
       " 'kind': 649,\n",
       " 'knees': 650,\n",
       " 'knew': 651,\n",
       " 'know': 652,\n",
       " 'known': 653,\n",
       " 'laid': 654,\n",
       " 'lair': 655,\n",
       " 'landing': 656,\n",
       " 'language': 657,\n",
       " 'last': 658,\n",
       " 'late': 659,\n",
       " 'later': 660,\n",
       " 'latter': 661,\n",
       " 'laugh': 662,\n",
       " 'laughed': 663,\n",
       " 'lay': 664,\n",
       " 'leading': 665,\n",
       " 'lean': 666,\n",
       " 'learned': 667,\n",
       " 'least': 668,\n",
       " 'leathery': 669,\n",
       " 'leave': 670,\n",
       " 'led': 671,\n",
       " 'left': 672,\n",
       " 'leisure': 673,\n",
       " 'lends': 674,\n",
       " 'lent': 675,\n",
       " 'let': 676,\n",
       " 'letters': 677,\n",
       " 'library': 678,\n",
       " 'license': 679,\n",
       " 'lies': 680,\n",
       " 'life': 681,\n",
       " 'life-likeness': 682,\n",
       " 'lift': 683,\n",
       " 'lifted': 684,\n",
       " 'light': 685,\n",
       " 'lightly': 686,\n",
       " 'like': 687,\n",
       " 'liked': 688,\n",
       " 'line': 689,\n",
       " 'lines': 690,\n",
       " 'lingered': 691,\n",
       " 'lips': 692,\n",
       " 'list': 693,\n",
       " 'lit': 694,\n",
       " 'little': 695,\n",
       " 'live': 696,\n",
       " 'll': 697,\n",
       " 'loathing': 698,\n",
       " 'long': 699,\n",
       " 'longed': 700,\n",
       " 'longer': 701,\n",
       " 'look': 702,\n",
       " 'looked': 703,\n",
       " 'looking': 704,\n",
       " 'lose': 705,\n",
       " 'loss': 706,\n",
       " 'lounging': 707,\n",
       " 'lovely': 708,\n",
       " 'lucky': 709,\n",
       " 'lump': 710,\n",
       " 'luncheon-table': 711,\n",
       " 'luxury': 712,\n",
       " 'lying': 713,\n",
       " 'made': 714,\n",
       " 'magazines': 715,\n",
       " 'make': 716,\n",
       " 'man': 717,\n",
       " 'manage': 718,\n",
       " 'managed': 719,\n",
       " 'mantel-piece': 720,\n",
       " 'marble': 721,\n",
       " 'married': 722,\n",
       " 'may': 723,\n",
       " 'me': 724,\n",
       " 'meant': 725,\n",
       " 'mediocrity': 726,\n",
       " 'medium': 727,\n",
       " 'members': 728,\n",
       " 'mentioned': 729,\n",
       " 'mere': 730,\n",
       " 'merely': 731,\n",
       " 'met': 732,\n",
       " 'might': 733,\n",
       " 'mighty': 734,\n",
       " 'millionaire': 735,\n",
       " 'mine': 736,\n",
       " 'minute': 737,\n",
       " 'minutes': 738,\n",
       " 'mirrors': 739,\n",
       " 'modest': 740,\n",
       " 'modesty': 741,\n",
       " 'moment': 742,\n",
       " 'money': 743,\n",
       " 'monumental': 744,\n",
       " 'mood': 745,\n",
       " 'morbidly': 746,\n",
       " 'more': 747,\n",
       " 'most': 748,\n",
       " 'mourn': 749,\n",
       " 'mourned': 750,\n",
       " 'moustache': 751,\n",
       " 'moved': 752,\n",
       " 'much': 753,\n",
       " 'muddling': 754,\n",
       " 'multilingual': 755,\n",
       " 'multiplied': 756,\n",
       " 'murmur': 757,\n",
       " 'muscles': 758,\n",
       " 'must': 759,\n",
       " 'my': 760,\n",
       " 'myself': 761,\n",
       " 'mysterious': 762,\n",
       " 'naive': 763,\n",
       " 'native': 764,\n",
       " 'near': 765,\n",
       " 'nearly': 766,\n",
       " 'negatived': 767,\n",
       " 'nervous': 768,\n",
       " 'nervousness': 769,\n",
       " 'neutral': 770,\n",
       " 'never': 771,\n",
       " 'new': 772,\n",
       " 'next': 773,\n",
       " 'no': 774,\n",
       " 'none': 775,\n",
       " 'not': 776,\n",
       " 'note': 777,\n",
       " 'nothing': 778,\n",
       " 'novels': 779,\n",
       " 'now': 780,\n",
       " 'nymphs': 781,\n",
       " 'oak': 782,\n",
       " 'obituary': 783,\n",
       " 'object': 784,\n",
       " 'objects': 785,\n",
       " 'occurred': 786,\n",
       " 'oddly': 787,\n",
       " 'of': 788,\n",
       " 'off': 789,\n",
       " 'often': 790,\n",
       " 'oh': 791,\n",
       " 'old': 792,\n",
       " 'omitted': 793,\n",
       " 'on': 794,\n",
       " 'once': 795,\n",
       " 'one': 796,\n",
       " 'ones': 797,\n",
       " 'online': 798,\n",
       " 'only': 799,\n",
       " 'onto': 800,\n",
       " 'open': 801,\n",
       " 'or': 802,\n",
       " 'other': 803,\n",
       " 'our': 804,\n",
       " 'ourselves': 805,\n",
       " 'out': 806,\n",
       " 'outline': 807,\n",
       " 'oval': 808,\n",
       " 'over': 809,\n",
       " 'own': 810,\n",
       " 'packed': 811,\n",
       " 'page': 812,\n",
       " 'paid': 813,\n",
       " 'paint': 814,\n",
       " 'painted': 815,\n",
       " 'painter': 816,\n",
       " 'painting': 817,\n",
       " 'pale': 818,\n",
       " 'paled': 819,\n",
       " 'palm-trees': 820,\n",
       " 'panel': 821,\n",
       " 'panelling': 822,\n",
       " 'pardonable': 823,\n",
       " 'pardoned': 824,\n",
       " 'part': 825,\n",
       " 'passages': 826,\n",
       " 'passing': 827,\n",
       " 'past': 828,\n",
       " 'pastels': 829,\n",
       " 'pathos': 830,\n",
       " 'patient': 831,\n",
       " 'people': 832,\n",
       " 'perceptible': 833,\n",
       " 'perfect': 834,\n",
       " 'persistence': 835,\n",
       " 'persuasively': 836,\n",
       " 'phrase': 837,\n",
       " 'picture': 838,\n",
       " 'pictures': 839,\n",
       " 'pines': 840,\n",
       " 'pink': 841,\n",
       " 'place': 842,\n",
       " 'placed': 843,\n",
       " 'plain': 844,\n",
       " 'platitudes': 845,\n",
       " 'pleased': 846,\n",
       " 'pockets': 847,\n",
       " 'poems': 848,\n",
       " 'point': 849,\n",
       " 'poised': 850,\n",
       " 'poor': 851,\n",
       " 'portrait': 852,\n",
       " 'posing': 853,\n",
       " 'possessed': 854,\n",
       " 'possible': 855,\n",
       " 'poverty': 856,\n",
       " 'predicted': 857,\n",
       " 'preliminary': 858,\n",
       " 'presenting': 859,\n",
       " 'prestidigitation': 860,\n",
       " 'pretty': 861,\n",
       " 'previous': 862,\n",
       " 'price': 863,\n",
       " 'pride': 864,\n",
       " 'princely': 865,\n",
       " 'prism': 866,\n",
       " 'problem': 867,\n",
       " 'proclaiming': 868,\n",
       " 'prodigious': 869,\n",
       " 'profusion': 870,\n",
       " 'proofreading': 871,\n",
       " 'protest': 872,\n",
       " 'prove': 873,\n",
       " 'public': 874,\n",
       " 'publications': 875,\n",
       " 'published': 876,\n",
       " 'purblind': 877,\n",
       " 'purely': 878,\n",
       " 'purpose': 879,\n",
       " 'pushed': 880,\n",
       " 'put': 881,\n",
       " 'qualities': 882,\n",
       " 'quality': 883,\n",
       " 'queerly': 884,\n",
       " 'question': 885,\n",
       " 'quickly': 886,\n",
       " 'quietly': 887,\n",
       " 'quite': 888,\n",
       " 'quote': 889,\n",
       " 'rain': 890,\n",
       " 'raised': 891,\n",
       " 'random': 892,\n",
       " 'rather': 893,\n",
       " 're': 894,\n",
       " 'real': 895,\n",
       " 'really': 896,\n",
       " 'reared': 897,\n",
       " 'reason': 898,\n",
       " 'reassurance': 899,\n",
       " 'recovering': 900,\n",
       " 'recreated': 901,\n",
       " 'reflected': 902,\n",
       " 'reflection': 903,\n",
       " 'regrets': 904,\n",
       " 'relatively': 905,\n",
       " 'remained': 906,\n",
       " 'remember': 907,\n",
       " 'reminded': 908,\n",
       " 'repeating': 909,\n",
       " 'report': 910,\n",
       " 'represented': 911,\n",
       " 'reproduction': 912,\n",
       " 'requested': 913,\n",
       " 'resented': 914,\n",
       " 'resolve': 915,\n",
       " 'resources': 916,\n",
       " 'rest': 917,\n",
       " 'rich': 918,\n",
       " 'ridiculous': 919,\n",
       " 'robbed': 920,\n",
       " 'romantic': 921,\n",
       " 'room': 922,\n",
       " 'rose': 923,\n",
       " 'rs': 924,\n",
       " 'rule': 925,\n",
       " 'run': 926,\n",
       " 's': 927,\n",
       " 'said': 928,\n",
       " 'same': 929,\n",
       " 'satisfaction': 930,\n",
       " 'savour': 931,\n",
       " 'saw': 932,\n",
       " 'say': 933,\n",
       " 'saying': 934,\n",
       " 'says': 935,\n",
       " 'scorn': 936,\n",
       " 'scornful': 937,\n",
       " 'secret': 938,\n",
       " 'see': 939,\n",
       " 'seemed': 940,\n",
       " 'seen': 941,\n",
       " 'self-confident': 942,\n",
       " 'send': 943,\n",
       " 'sensation': 944,\n",
       " 'sensitive': 945,\n",
       " 'sent': 946,\n",
       " 'serious': 947,\n",
       " 'set': 948,\n",
       " 'sex': 949,\n",
       " 'shade': 950,\n",
       " 'shaking': 951,\n",
       " 'shall': 952,\n",
       " 'she': 953,\n",
       " 'shirked': 954,\n",
       " 'short': 955,\n",
       " 'shorter': 956,\n",
       " 'should': 957,\n",
       " 'shoulder': 958,\n",
       " 'shoulders': 959,\n",
       " 'show': 960,\n",
       " 'showed': 961,\n",
       " 'showy': 962,\n",
       " 'shrug': 963,\n",
       " 'shrugged': 964,\n",
       " 'sight': 965,\n",
       " 'sign': 966,\n",
       " 'silent': 967,\n",
       " 'silver': 968,\n",
       " 'similar': 969,\n",
       " 'simpleton': 970,\n",
       " 'simplifications': 971,\n",
       " 'simply': 972,\n",
       " 'since': 973,\n",
       " 'single': 974,\n",
       " 'sitter': 975,\n",
       " 'sitters': 976,\n",
       " 'sketch': 977,\n",
       " 'skill': 978,\n",
       " 'slight': 979,\n",
       " 'slightly': 980,\n",
       " 'slowly': 981,\n",
       " 'small': 982,\n",
       " 'smile': 983,\n",
       " 'smiling': 984,\n",
       " 'sneer': 985,\n",
       " 'so': 986,\n",
       " 'solace': 987,\n",
       " 'some': 988,\n",
       " 'somebody': 989,\n",
       " 'something': 990,\n",
       " 'spacious': 991,\n",
       " 'spaniel': 992,\n",
       " 'speaking-tubes': 993,\n",
       " 'speculations': 994,\n",
       " 'spite': 995,\n",
       " 'splash': 996,\n",
       " 'square': 997,\n",
       " 'stairs': 998,\n",
       " 'stammer': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"The_Verdict.txt\", \"r\", encoding=\"utf=8\") as f: \n",
    "    text = f.read() \n",
    "    \n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "preprocessed = [item for item in result if item.strip()]                #further remove whitespaces from string list \n",
    "all_tokens = sorted(list(set(preprocessed)))               # set() builds a hash set, and list() makes the set into a list. \n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - Instantiate an object \n",
    "tokenizer = SimpleTokenizer(vocab) \n",
    "ids = tokenizer.encode(text) \n",
    "\n",
    "ecoded_text = tokenizer.decode(ids) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[113,\n",
       " 127,\n",
       " 46,\n",
       " 132,\n",
       " 12,\n",
       " 48,\n",
       " 532,\n",
       " 136,\n",
       " 794,\n",
       " 105,\n",
       " 11,\n",
       " 6,\n",
       " 14,\n",
       " 70,\n",
       " 61,\n",
       " 177,\n",
       " 1084,\n",
       " 74,\n",
       " 55,\n",
       " 893,\n",
       " 142,\n",
       " 289,\n",
       " 541,\n",
       " 7,\n",
       " 1083,\n",
       " 142,\n",
       " 555,\n",
       " 488,\n",
       " 443,\n",
       " 7,\n",
       " 986,\n",
       " 641,\n",
       " 1162,\n",
       " 774,\n",
       " 563,\n",
       " 1040,\n",
       " 1097,\n",
       " 724,\n",
       " 1097,\n",
       " 590,\n",
       " 1068,\n",
       " 6,\n",
       " 623,\n",
       " 1069,\n",
       " 593,\n",
       " 788,\n",
       " 604,\n",
       " 551,\n",
       " 6,\n",
       " 588,\n",
       " 569,\n",
       " 418,\n",
       " 604,\n",
       " 817,\n",
       " 6,\n",
       " 722,\n",
       " 142,\n",
       " 918,\n",
       " 1188,\n",
       " 6,\n",
       " 185,\n",
       " 449,\n",
       " 602,\n",
       " 623,\n",
       " 142,\n",
       " 1150,\n",
       " 794,\n",
       " 1069,\n",
       " 102,\n",
       " 8,\n",
       " 3,\n",
       " 119,\n",
       " 70,\n",
       " 893,\n",
       " 1084,\n",
       " 641,\n",
       " 1207,\n",
       " 585,\n",
       " 238,\n",
       " 103,\n",
       " 802,\n",
       " 50,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 113,\n",
       " 593,\n",
       " 788,\n",
       " 604,\n",
       " 551,\n",
       " 1,\n",
       " 7,\n",
       " 1068,\n",
       " 1162,\n",
       " 1175,\n",
       " 1069,\n",
       " 1198,\n",
       " 275,\n",
       " 641,\n",
       " 8,\n",
       " 70,\n",
       " 277,\n",
       " 590,\n",
       " 85,\n",
       " 8,\n",
       " 54,\n",
       " 120,\n",
       " 7,\n",
       " 604,\n",
       " 658,\n",
       " 35,\n",
       " 975,\n",
       " 7,\n",
       " 370,\n",
       " 604,\n",
       " 1124,\n",
       " 143,\n",
       " 8,\n",
       " 1,\n",
       " 91,\n",
       " 341,\n",
       " 641,\n",
       " 2,\n",
       " 927,\n",
       " 553,\n",
       " 1097,\n",
       " 943,\n",
       " 1069,\n",
       " 1143,\n",
       " 788,\n",
       " 760,\n",
       " 838,\n",
       " 2,\n",
       " 1168,\n",
       " 1218,\n",
       " 272,\n",
       " 70,\n",
       " 407,\n",
       " 2,\n",
       " 1049,\n",
       " 1079,\n",
       " 788,\n",
       " 1068,\n",
       " 6,\n",
       " 84,\n",
       " 8,\n",
       " 101,\n",
       " 7,\n",
       " 1069,\n",
       " 706,\n",
       " 1097,\n",
       " 25,\n",
       " 640,\n",
       " 173,\n",
       " 70,\n",
       " 1079,\n",
       " 788,\n",
       " 8,\n",
       " 1,\n",
       " 113,\n",
       " 1202,\n",
       " 6,\n",
       " 794,\n",
       " 85,\n",
       " 8,\n",
       " 120,\n",
       " 2,\n",
       " 927,\n",
       " 692,\n",
       " 6,\n",
       " 756,\n",
       " 642,\n",
       " 141,\n",
       " 924,\n",
       " 141,\n",
       " 207,\n",
       " 1083,\n",
       " 1075,\n",
       " 1174,\n",
       " 902,\n",
       " 623,\n",
       " 184,\n",
       " 440,\n",
       " 1153,\n",
       " 788,\n",
       " 739,\n",
       " 8,\n",
       " 23,\n",
       " 641,\n",
       " 1162,\n",
       " 776,\n",
       " 799,\n",
       " 1069,\n",
       " 85,\n",
       " 8,\n",
       " 121,\n",
       " 1183,\n",
       " 750,\n",
       " 8,\n",
       " 62,\n",
       " 776,\n",
       " 1069,\n",
       " 463,\n",
       " 67,\n",
       " 40,\n",
       " 6,\n",
       " 210,\n",
       " 1069,\n",
       " 658,\n",
       " 57,\n",
       " 53,\n",
       " 960,\n",
       " 6,\n",
       " 1008,\n",
       " 724,\n",
       " 239,\n",
       " 55,\n",
       " 2,\n",
       " 927,\n",
       " 1,\n",
       " 83,\n",
       " 1,\n",
       " 1097,\n",
       " 933,\n",
       " 6,\n",
       " 1194,\n",
       " 1055,\n",
       " 623,\n",
       " 594,\n",
       " 1218,\n",
       " 1,\n",
       " 130,\n",
       " 952,\n",
       " 776,\n",
       " 702,\n",
       " 1135,\n",
       " 642,\n",
       " 687,\n",
       " 168,\n",
       " 1,\n",
       " 18,\n",
       " 131,\n",
       " 0,\n",
       " 7,\n",
       " 451,\n",
       " 1088,\n",
       " 1069,\n",
       " 866,\n",
       " 788,\n",
       " 67,\n",
       " 2,\n",
       " 927,\n",
       " 1055,\n",
       " 70,\n",
       " 489,\n",
       " 144,\n",
       " 1097,\n",
       " 471,\n",
       " 1069,\n",
       " 473,\n",
       " 1194,\n",
       " 446,\n",
       " 8,\n",
       " 98,\n",
       " 74,\n",
       " 55,\n",
       " 0,\n",
       " 113,\n",
       " 1198,\n",
       " 569,\n",
       " 714,\n",
       " 601,\n",
       " 7,\n",
       " 641,\n",
       " 1162,\n",
       " 497,\n",
       " 1068,\n",
       " 1075,\n",
       " 957,\n",
       " 749,\n",
       " 601,\n",
       " 8,\n",
       " 22,\n",
       " 604,\n",
       " 810,\n",
       " 949,\n",
       " 491,\n",
       " 904,\n",
       " 1174,\n",
       " 591,\n",
       " 6,\n",
       " 185,\n",
       " 623,\n",
       " 604,\n",
       " 810,\n",
       " 1107,\n",
       " 583,\n",
       " 142,\n",
       " 757,\n",
       " 8,\n",
       " 99,\n",
       " 645,\n",
       " 18,\n",
       " 97,\n",
       " 8,\n",
       " 71,\n",
       " 641,\n",
       " 1174,\n",
       " 6,\n",
       " 1069,\n",
       " 608,\n",
       " 788,\n",
       " 1069,\n",
       " 343,\n",
       " 1162,\n",
       " 1151,\n",
       " 274,\n",
       " 695,\n",
       " 36,\n",
       " 90,\n",
       " 6,\n",
       " 1183,\n",
       " 6,\n",
       " 623,\n",
       " 173,\n",
       " 555,\n",
       " 478,\n",
       " 6,\n",
       " 266,\n",
       " 806,\n",
       " 623,\n",
       " 1069,\n",
       " 31,\n",
       " 142,\n",
       " 1149,\n",
       " 578,\n",
       " 1,\n",
       " 783,\n",
       " 1,\n",
       " 794,\n",
       " 74,\n",
       " 7,\n",
       " 796,\n",
       " 788,\n",
       " 1082,\n",
       " 962,\n",
       " 205,\n",
       " 1006,\n",
       " 1194,\n",
       " 892,\n",
       " 1056,\n",
       " 1068,\n",
       " 70,\n",
       " 585,\n",
       " 591,\n",
       " 3,\n",
       " 70,\n",
       " 1199,\n",
       " 2,\n",
       " 1049,\n",
       " 933,\n",
       " 274,\n",
       " 1185,\n",
       " 4,\n",
       " 319,\n",
       " 1097,\n",
       " 55,\n",
       " 2,\n",
       " 927,\n",
       " 817,\n",
       " 8,\n",
       " 23,\n",
       " 986,\n",
       " 7,\n",
       " 604,\n",
       " 915,\n",
       " 243,\n",
       " 193,\n",
       " 639,\n",
       " 7,\n",
       " 1069,\n",
       " 391,\n",
       " 560,\n",
       " 382,\n",
       " 806,\n",
       " 6,\n",
       " 185,\n",
       " 6,\n",
       " 207,\n",
       " 85,\n",
       " 8,\n",
       " 120,\n",
       " 569,\n",
       " 857,\n",
       " 6,\n",
       " 1069,\n",
       " 863,\n",
       " 788,\n",
       " 1,\n",
       " 56,\n",
       " 1,\n",
       " 1173,\n",
       " 1133,\n",
       " 8,\n",
       " 73,\n",
       " 1162,\n",
       " 776,\n",
       " 1091,\n",
       " 1085,\n",
       " 1210,\n",
       " 660,\n",
       " 1068,\n",
       " 6,\n",
       " 623,\n",
       " 1069,\n",
       " 341,\n",
       " 788,\n",
       " 142,\n",
       " 490,\n",
       " 1171,\n",
       " 2,\n",
       " 620,\n",
       " 794,\n",
       " 1069,\n",
       " 102,\n",
       " 6,\n",
       " 641,\n",
       " 1029,\n",
       " 786,\n",
       " 1097,\n",
       " 724,\n",
       " 1097,\n",
       " 1200,\n",
       " 1186,\n",
       " 55,\n",
       " 569,\n",
       " 546,\n",
       " 1133,\n",
       " 604,\n",
       " 817,\n",
       " 8,\n",
       " 93,\n",
       " 903,\n",
       " 6,\n",
       " 641,\n",
       " 896,\n",
       " 1162,\n",
       " 142,\n",
       " 1060,\n",
       " 867,\n",
       " 8,\n",
       " 122,\n",
       " 153,\n",
       " 604,\n",
       " 1189,\n",
       " 1207,\n",
       " 585,\n",
       " 238,\n",
       " 1101,\n",
       " 425,\n",
       " 7,\n",
       " 604,\n",
       " 477,\n",
       " 976,\n",
       " 569,\n",
       " 238,\n",
       " 369,\n",
       " 1069,\n",
       " 987,\n",
       " 788,\n",
       " 934,\n",
       " 1068,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 569,\n",
       " 1,\n",
       " 412,\n",
       " 601,\n",
       " 410,\n",
       " 8,\n",
       " 1,\n",
       " 51,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 7,\n",
       " 207,\n",
       " 1028,\n",
       " 7,\n",
       " 569,\n",
       " 776,\n",
       " 460,\n",
       " 1091,\n",
       " 766,\n",
       " 142,\n",
       " 1209,\n",
       " 166,\n",
       " 74,\n",
       " 2,\n",
       " 927,\n",
       " 915,\n",
       " 569,\n",
       " 238,\n",
       " 1052,\n",
       " 8,\n",
       " 73,\n",
       " 733,\n",
       " 228,\n",
       " 1068,\n",
       " 588,\n",
       " 569,\n",
       " 722,\n",
       " 594,\n",
       " 7,\n",
       " 973,\n",
       " 588,\n",
       " 688,\n",
       " 604,\n",
       " 423,\n",
       " 7,\n",
       " 235,\n",
       " 588,\n",
       " 381,\n",
       " 2,\n",
       " 1049,\n",
       " 1159,\n",
       " 1097,\n",
       " 552,\n",
       " 794,\n",
       " 1218,\n",
       " 272,\n",
       " 641,\n",
       " 1207,\n",
       " 585,\n",
       " 238,\n",
       " 582,\n",
       " 1097,\n",
       " 873,\n",
       " 1068,\n",
       " 588,\n",
       " 569,\n",
       " 546,\n",
       " 1133,\n",
       " 604,\n",
       " 817,\n",
       " 235,\n",
       " 588,\n",
       " 569,\n",
       " 722,\n",
       " 594,\n",
       " 8,\n",
       " 91,\n",
       " 341,\n",
       " 6,\n",
       " 621,\n",
       " 953,\n",
       " 569,\n",
       " 776,\n",
       " 412,\n",
       " 601,\n",
       " 410,\n",
       " 6,\n",
       " 953,\n",
       " 569,\n",
       " 445,\n",
       " 6,\n",
       " 207,\n",
       " 80,\n",
       " 40,\n",
       " 327,\n",
       " 6,\n",
       " 475,\n",
       " 1097,\n",
       " 1,\n",
       " 683,\n",
       " 601,\n",
       " 1133,\n",
       " 1,\n",
       " 7,\n",
       " 953,\n",
       " 569,\n",
       " 776,\n",
       " 671,\n",
       " 601,\n",
       " 221,\n",
       " 1097,\n",
       " 1069,\n",
       " 424,\n",
       " 8,\n",
       " 122,\n",
       " 881,\n",
       " 1069,\n",
       " 268,\n",
       " 635,\n",
       " 604,\n",
       " 576,\n",
       " 168,\n",
       " 7,\n",
       " 1175,\n",
       " 142,\n",
       " 1154,\n",
       " 510,\n",
       " 142,\n",
       " 1189,\n",
       " 0,\n",
       " 32,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 195,\n",
       " 1097,\n",
       " 585,\n",
       " 393,\n",
       " 641,\n",
       " 7,\n",
       " 185,\n",
       " 70,\n",
       " 489,\n",
       " 641,\n",
       " 733,\n",
       " 228,\n",
       " 634,\n",
       " 1097,\n",
       " 493,\n",
       " 806,\n",
       " 1186,\n",
       " 8,\n",
       " 113,\n",
       " 376,\n",
       " 681,\n",
       " 788,\n",
       " 1069,\n",
       " 102,\n",
       " 674,\n",
       " 643,\n",
       " 1097,\n",
       " 1028,\n",
       " 878,\n",
       " 151,\n",
       " 1218,\n",
       " 185,\n",
       " 587,\n",
       " 6,\n",
       " 794,\n",
       " 760,\n",
       " 1168,\n",
       " 1097,\n",
       " 82,\n",
       " 34,\n",
       " 6,\n",
       " 283,\n",
       " 142,\n",
       " 549,\n",
       " 788,\n",
       " 74,\n",
       " 2,\n",
       " 927,\n",
       " 225,\n",
       " 1065,\n",
       " 248,\n",
       " 1069,\n",
       " 840,\n",
       " 6,\n",
       " 70,\n",
       " 569,\n",
       " 761,\n",
       " 256,\n",
       " 1081,\n",
       " 1069,\n",
       " 773,\n",
       " 359,\n",
       " 8,\n",
       " 70,\n",
       " 523,\n",
       " 1069,\n",
       " 340,\n",
       " 210,\n",
       " 1054,\n",
       " 245,\n",
       " 1070,\n",
       " 1218,\n",
       " 185,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 2,\n",
       " 927,\n",
       " 1172,\n",
       " 1162,\n",
       " 986,\n",
       " 540,\n",
       " 1068,\n",
       " 6,\n",
       " 623,\n",
       " 1069,\n",
       " 444,\n",
       " 1171,\n",
       " 6,\n",
       " 70,\n",
       " 302,\n",
       " 641,\n",
       " 530,\n",
       " 8,\n",
       " 73,\n",
       " 1162,\n",
       " 776,\n",
       " 1068,\n",
       " 760,\n",
       " 610,\n",
       " 1162,\n",
       " 1,\n",
       " 634,\n",
       " 1,\n",
       " 16,\n",
       " 794,\n",
       " 1068,\n",
       " 849,\n",
       " 70,\n",
       " 335,\n",
       " 585,\n",
       " 546,\n",
       " 80,\n",
       " 40,\n",
       " 1069,\n",
       " 534,\n",
       " 899,\n",
       " 8,\n",
       " 73,\n",
       " 1162,\n",
       " 646,\n",
       " 235,\n",
       " 953,\n",
       " 1162,\n",
       " 141,\n",
       " 776,\n",
       " 141,\n",
       " 634,\n",
       " 7,\n",
       " 621,\n",
       " 70,\n",
       " 723,\n",
       " 228,\n",
       " 824,\n",
       " 1069,\n",
       " 270,\n",
       " 7,\n",
       " 1068,\n",
       " 70,\n",
       " 523,\n",
       " 594,\n",
       " 986,\n",
       " 8,\n",
       " 51,\n",
       " 74,\n",
       " 6,\n",
       " 173,\n",
       " 604,\n",
       " 681,\n",
       " 6,\n",
       " 569,\n",
       " 238,\n",
       " 1042,\n",
       " 274,\n",
       " 634,\n",
       " 1218,\n",
       " 1075,\n",
       " 569,\n",
       " 522,\n",
       " 604,\n",
       " 204,\n",
       " 6,\n",
       " 641,\n",
       " 569,\n",
       " 238,\n",
       " 897,\n",
       " 623,\n",
       " 1069,\n",
       " 611,\n",
       " 788,\n",
       " 1070,\n",
       " 161,\n",
       " 8,\n",
       " 23,\n",
       " 641,\n",
       " 1162,\n",
       " 1074,\n",
       " 633,\n",
       " 1097,\n",
       " 777,\n",
       " 1175,\n",
       " 429,\n",
       " 1069,\n",
       " 1,\n",
       " 362,\n",
       " 211,\n",
       " 788,\n",
       " 726,\n",
       " 1,\n",
       " 3,\n",
       " 70,\n",
       " 889,\n",
       " 80,\n",
       " 40,\n",
       " 4,\n",
       " 1162,\n",
       " 587,\n",
       " 794,\n",
       " 601,\n",
       " 8,\n",
       " 70,\n",
       " 585,\n",
       " 729,\n",
       " 1068,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 1162,\n",
       " 1218,\n",
       " 185,\n",
       " 641,\n",
       " 1162,\n",
       " 622,\n",
       " 833,\n",
       " 1068,\n",
       " 594,\n",
       " 617,\n",
       " 1162,\n",
       " 467,\n",
       " 532,\n",
       " 1080,\n",
       " 300,\n",
       " 142,\n",
       " 367,\n",
       " 272,\n",
       " 1026,\n",
       " 930,\n",
       " 8,\n",
       " 73,\n",
       " 640,\n",
       " 6,\n",
       " 207,\n",
       " 142,\n",
       " 925,\n",
       " 6,\n",
       " 1069,\n",
       " 832,\n",
       " 1183,\n",
       " 936,\n",
       " 743,\n",
       " 1183,\n",
       " 543,\n",
       " 748,\n",
       " 806,\n",
       " 788,\n",
       " 1218,\n",
       " 185,\n",
       " 74,\n",
       " 2,\n",
       " 927,\n",
       " 435,\n",
       " 392,\n",
       " 788,\n",
       " 604,\n",
       " 1189,\n",
       " 2,\n",
       " 927,\n",
       " 249,\n",
       " 223,\n",
       " 438,\n",
       " 601,\n",
       " 6,\n",
       " 1194,\n",
       " 184,\n",
       " 194,\n",
       " 788,\n",
       " 834,\n",
       " 556,\n",
       " 6,\n",
       " 1097,\n",
       " 1109,\n",
       " 641,\n",
       " 635,\n",
       " 785,\n",
       " 788,\n",
       " 204,\n",
       " 185,\n",
       " 712,\n",
       " 8,\n",
       " 122,\n",
       " 1069,\n",
       " 661,\n",
       " 6,\n",
       " 70,\n",
       " 759,\n",
       " 157,\n",
       " 6,\n",
       " 588,\n",
       " 906,\n",
       " 905,\n",
       " 1218,\n",
       " 272,\n",
       " 588,\n",
       " 1162,\n",
       " 273,\n",
       " 100,\n",
       " 265,\n",
       " 185,\n",
       " 433,\n",
       " 839,\n",
       " 1194,\n",
       " 142,\n",
       " 390,\n",
       " 1068,\n",
       " 246,\n",
       " 1069,\n",
       " 182,\n",
       " 916,\n",
       " 8,\n",
       " 1,\n",
       " 81,\n",
       " 2,\n",
       " 927,\n",
       " 799,\n",
       " 458,\n",
       " 640,\n",
       " 1097,\n",
       " 881,\n",
       " 233,\n",
       " 635,\n",
       " 299,\n",
       " 6,\n",
       " 1,\n",
       " 1162,\n",
       " 796,\n",
       " 788,\n",
       " 1069,\n",
       " 219,\n",
       " 588,\n",
       " 654,\n",
       " 410,\n",
       " 155,\n",
       " 1069,\n",
       " 106,\n",
       " 185,\n",
       " 968,\n",
       " 788,\n",
       " 184,\n",
       " 464,\n",
       " 197,\n",
       " 711,\n",
       " 6,\n",
       " 1176,\n",
       " 6,\n",
       " 794,\n",
       " 142,\n",
       " 660,\n",
       " 359,\n",
       " 6,\n",
       " 70,\n",
       " 569,\n",
       " 168,\n",
       " 926,\n",
       " 809,\n",
       " 532,\n",
       " 82,\n",
       " 1218,\n",
       " 185,\n",
       " 85,\n",
       " 8,\n",
       " 55,\n",
       " 6,\n",
       " 229,\n",
       " 794,\n",
       " 601,\n",
       " 6,\n",
       " 158,\n",
       " 510,\n",
       " 760,\n",
       " 1218,\n",
       " 1,\n",
       " 74,\n",
       " 640,\n",
       " 986,\n",
       " 746,\n",
       " 945,\n",
       " 1097,\n",
       " 455,\n",
       " 518,\n",
       " 788,\n",
       " 233,\n",
       " 8,\n",
       " 1,\n",
       " 98,\n",
       " 74,\n",
       " 0,\n",
       " 73,\n",
       " 569,\n",
       " 177,\n",
       " 238,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoded_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecoded_text\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_text' is not defined"
     ]
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1214)\n",
      "('your', 1215)\n",
      "('yourself', 1216)\n",
      "('<|endoftext|>', 1217)\n",
      "('<|unk|>', 1218)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "# Test end of text token in the case of additional test source\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1218, 6, 402, 1213, 687, 1054, 18, 1217, 72, 1069, 1035, 1065, 788, 1069, 1218, 8]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer(vocab)\n",
    "print(tokenizer.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST - Byte Pair Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 262, 20562, 13]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\") \n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKwirw ier'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"AKwirw ier\"\n",
    "integers = tokenizer.encode(text)\n",
    "tokenizer.decode(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  464,  4643, 11600,   628]]),\n",
       " tensor([[ 4643, 11600,   628,   198]])]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"The_Verdict.txt\", 'r', encoding=\"utf=8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "first_batch\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_batch = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 4643, 11600,   628,   198]]),\n",
       " tensor([[11600,   628,   198,   197]])]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch # Each stride is a representation of the next context window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[  464,  4643, 11600,   628],\n",
      "        [  198,   197,   197,   197],\n",
      "        [  197,   197,  7407,   342],\n",
      "        [  854, 41328,   628,   628],\n",
      "        [  198,   198,  1129,  2919],\n",
      "        [  628,   628,   198,   198],\n",
      "        [ 3109,  9213,   422, 11145],\n",
      "        [  271,  1668,   319,  2693]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 4643, 11600,   628,   198],\n",
      "        [  197,   197,   197,   197],\n",
      "        [  197,  7407,   342,   854],\n",
      "        [41328,   628,   628,   198],\n",
      "        [  198,  1129,  2919,   628],\n",
      "        [  628,   198,   198,  3109],\n",
      "        [ 9213,   422, 11145,   271],\n",
      "        [ 1668,   319,  2693,  1467]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter) \n",
    "print(\"Inputs:\\n\", inputs) \n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing embedded vectors, the input variables where the weights later gets applied to\n",
    "\n",
    "inputs_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.2753, -0.2010,  0.9624],\n",
      "        [ 0.2492, -0.4845, -2.0929],\n",
      "        [-0.8199, -0.4210, -0.9620],\n",
      "        [ 1.2825, -0.3430, -0.6821],\n",
      "        [-0.9887, -1.7018, -0.7498],\n",
      "        [-1.1285,  0.4135,  0.2892]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6 \n",
    "output_dim = 3 \n",
    " \n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2825, -0.3430, -0.6821]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[  922,    12, 49705,    11],\n",
      "        [  438,  4360,   612,   338],\n",
      "        [  612,  1997,   319,  4534],\n",
      "        [  407,  2957,   683,   736],\n",
      "        [16957,  1696,   414,     1],\n",
      "        [11978,  2119,    11,   351],\n",
      "        [ 2060,   530,   287,   262],\n",
      "        [   11,   262, 15910,   286]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle = True)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "    [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "    [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "    [0.22, 0.58, 0.33], # with     (x^4)\n",
    "    [0.77, 0.25, 0.10], # one      (x^5)\n",
    "    [0.05, 0.80, 0.55]  # step     (x^6)\n",
    "    ])\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate attention scores \n",
    "# This process effectively takes the dot product of each embedded query token and takes the dot product including itself to compute a attention score\n",
    "# An attention score is to guage the similarity between the current embedded vector with respect to all the embedded vector including itself.\n",
    "\n",
    "\n",
    "# Here we are calculating the intermediate attention scores for one of the query token \n",
    "\n",
    "query = inputs[1] # Taking the embedded vector of index 1 as the query token \n",
    "\n",
    "attn_score_2 = torch.empty(inputs.shape[0]) # Create a data structure to hold the attention score of the embedded vector with respect to each input vector in this iteration\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_score_2[i] = torch.dot(x_i, query) \n",
    " \n",
    "attn_score_2 # attention score of the query embedded vector with respect to each input embedded vector\n",
    "\n",
    "# Each scalar product is a representation of how similar or aligned between the query and input embedded vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Score:  tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention Score: \", attn_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Attention weights are derived by normalizing the attention scores\n",
    "# all the attention weights should sum up to one\n",
    "\n",
    "attn_weights_2_tmp = attn_score_2 / attn_score_2.sum() \n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())\n",
    "\n",
    "# This normalization technique is not the most optimal. Only used for interpretiability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Usually normalization is achieved through softmax\n",
    "\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive = softmax_naive(attn_score_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    " \n",
    "print(\"Sum:\", attn_weights_2_naive.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Its also better to use the softmax function since it prevents under and overflow. Pytorch highly optimized it.\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_score_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_scores = torch.empty(6,6)\n",
    "for i, x_j in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        atten_scores[i, j] = torch.dot(x_i, x_j)\n",
    "        \n",
    "        \n",
    "atten_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code above can be written use @ which is faster for matrix multiplication\n",
    "\n",
    "atten_scores = inputs @ inputs.T\n",
    "atten_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_weights = torch.softmax(atten_scores, dim=1)\n",
    "atten_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that rows sum up to one \n",
    "sum_2_row = sum([0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452])\n",
    "sum_2_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all rows sum to 1 \n",
    "\n",
    "atten_weights.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_context_vecs = atten_weights @ inputs\n",
    "all_context_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Creating Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 # the output embedding size, d=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4300, 0.1500, 0.8900],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]]),\n",
       " tensor([0.5500, 0.8700, 0.6600]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]),\n",
       " Parameter containing:\n",
       " tensor([[0.2961, 0.5166],\n",
       "         [0.2517, 0.6886],\n",
       "         [0.0740, 0.8665]]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "\n",
    "W_query.shape, W_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "# After creating weight matricies you multiply them each into copies of input vectors to create q,k,v vectors\n",
    "\n",
    "query_2 = x_2 @ W_query # _2 because it's with respect to the 2nd input element\n",
    "key_2 = x_2 @ W_key \n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# The dot product of the key and query vector together is the the attention score\n",
    "keys_2 = keys[1] # Python starts index at 0\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# Since we have 6 inputs embedded vector againt 1 embedded vector there would need to be 6 attention scores\n",
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
    "print(attn_scores_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "# After computing the attention score we find the attention weight by normalizing the values with softmax\n",
    "\n",
    "# The difference to earlier is that we now scale the attention scores by dividing them by the square root of the embedding dimension, \n",
    "#  (i.e., d_k**0.5):\n",
    "\n",
    "d_k = keys.shape[1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "# Now we compute the context vector by multiplying each value vector within the context window with the current respective weight and then summming them to obtain the context vector\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 # the output embedding size, d=2\n",
    "\n",
    "d_in, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         context_vec \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m@\u001b[39m values\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context_vec\n\u001b[0;32m---> 19\u001b[0m x_2 \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# second input element\u001b[39;00m\n\u001b[1;32m     20\u001b[0m d_in \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# the input embedding size, d=3\u001b[39;00m\n\u001b[1;32m     21\u001b[0m d_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# the output embedding size, d=2\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sa_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reuse the query and key weight matrices of the\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# SelfAttention_v2 object from the previous section for convenience\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[43msa_v2\u001b[49m\u001b[38;5;241m.\u001b[39mW_query(inputs)\n\u001b[1;32m      4\u001b[0m keys \u001b[38;5;241m=\u001b[39m sa_v2\u001b[38;5;241m.\u001b[39mW_key(inputs) \n\u001b[1;32m      5\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m queries \u001b[38;5;241m@\u001b[39m keys\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sa_v2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reuse the query and key weight matrices of the\n",
    "# SelfAttention_v2 object from the previous section for convenience\n",
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
